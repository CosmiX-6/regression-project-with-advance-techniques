{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8638af0b-2a4d-4596-8f4c-4b8447bd6c9a",
   "metadata": {},
   "source": [
    "# Preprocessing of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2413eea-8682-44d4-889c-01b74e8a6efe",
   "metadata": {},
   "source": [
    "_Below is a function to count the Categorical and Numerical columns_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6eb1f5c-fb03-48b5-b031-5c6e69813371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "# Creating a function that will track quantitative and qualitative data\n",
    "def count_cols(dataframe):\n",
    "    '''\n",
    "    This function returns the counts of numeric and categorical data columns. \n",
    "    '''\n",
    "    \n",
    "    # creating dataframe with numeric data\n",
    "    quantitative_cols = dataframe.select_dtypes(include=[np.number])\n",
    "\n",
    "    # creating dataframe with categorical data\n",
    "    qualitative_cols = dataframe.select_dtypes(exclude=[np.number])\n",
    "\n",
    "    # printing the counts of numeric and categorical data\n",
    "    return [f'There are {quantitative_cols.shape[1]} numeric columns and \\\n",
    "{qualitative_cols.shape[1]} categorical columns.', quantitative_cols, qualitative_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4480787a-b686-47ab-b812-907d0ec93b8e",
   "metadata": {},
   "source": [
    "As this is a test dataset we wont change any true value here or drop any rows, we will just transform the dataset into required feature for testing the model, we will process the data by filling some NA values and transforming few skewed data as we did for training set. We are doing this because our model is trained on the instruction provided as input features, so that is what we also require in test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c805e4-94f8-4892-9233-e6a383865ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with importing required library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read the dataset!\n",
    "df = pd.read_csv('assets/data/Housing_Price_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8640d041-680e-4dba-85c0-c71a466d1005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies has been imported successfully.\n",
      "Testing Dataset has been read successfully.\n",
      "Rows : 1459\n",
      "Columns : 80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 87 numeric columns and 0 categorical columns.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Pacakges\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Configuring libs\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Dependencies has been imported successfully.')\n",
    "\n",
    "# Reading Dataset\n",
    "\n",
    "# Test Data\n",
    "df_test = pd.read_csv(r'assets/data/Housing_Price_Test.csv')\n",
    "df_test.head()\n",
    "print(f'Testing Dataset has been read successfully.\\nRows : {df_test.shape[0]}\\nColumns : {df_test.shape[1]}')\n",
    "\n",
    "# Checking for the presence of duplicate entry\n",
    "df_test.duplicated('Id').sum()\n",
    "\n",
    "\n",
    "# Deleting 'Id' Column\n",
    "del df_test['Id']\n",
    "\n",
    "# Replacing Nan value\n",
    "\n",
    "# For below column with missing values we have an option to replace the missing values wiht 'NA'\n",
    "# as 'NA' is a choice available for readings of those columns\n",
    "# So, we consider that 'Nan' values was something that wasn't applicable for the respective house.\n",
    "for col in ['Alley', 'PoolQC', 'MiscFeature', 'Fence', 'FireplaceQu', 'GarageCond', 'GarageType', 'GarageFinish', 'GarageQual', 'BsmtExposure', 'BsmtFinType2', 'BsmtCond', 'BsmtQual', 'BsmtFinType1', ]:\n",
    "    df_test[col].fillna('NA', inplace=True)\n",
    "    \n",
    "# Similar to previous case, this column has choice 'None' equivalent to 'NA'\n",
    "# So, we consider to replace it with 'None'\n",
    "df_test['MasVnrType'].fillna('None', inplace=True)\n",
    "\n",
    "# Filling 'Nan' values of below listed column with mean\n",
    "df_test['LotFrontage'] = df_test.groupby('Street')['LotFrontage'].transform(lambda x:x.fillna(x.mean()))\n",
    "df_test['MasVnrArea'] = df_test.groupby('MasVnrType')['MasVnrArea'].transform(lambda x:x.fillna(x.mean()))\n",
    "df_test['GarageYrBlt'] = df_test.groupby('GarageQual')['GarageYrBlt'].transform(lambda x:x.fillna(x.mode()))\n",
    "\n",
    "# Converting behaviour of 'MoSold' from numerical to categorical\n",
    "df_test['MoSold'] = df_test['MoSold'].apply(lambda x: str(x))\n",
    "\n",
    "# Lets add some new columns into dataframe using previous columns.<br>\n",
    "# For e.g. :\n",
    "#    - HouseAge & GarageAge : This will define how many year old the house & garage is.\n",
    "#    - TotalBath : We can sum up the total bathroom available in the house.\n",
    "#    - 2FlrBld : It tells whether the house has 2 floor or not.\n",
    "#      and many other.\n",
    "\n",
    "# Adding new columns\n",
    "\n",
    "# How many year old the houses are ?\n",
    "df_test['HouseAge'] = df_test['YrSold'] - df_test['YearRemodAdd'] \n",
    "\n",
    "# How many year old the garages are ?\n",
    "df_test['GarageAge'] = df_test['YrSold'] - df_test['GarageYrBlt']\n",
    "# Replacing leftover 'Nan' values with 0, for the houses that do not have garage\n",
    "df_test['GarageAge'].fillna(0, inplace=True) \n",
    "\n",
    "# Consdering Total Bathrooms Available in the house\n",
    "df_test['TotalBath'] = df_test['BsmtFullBath'] + df_test['FullBath'] + df_test['BsmtHalfBath']*0.5 + df_test['HalfBath']*0.5\n",
    "\n",
    "# Considering Total Porch Square Ft.\n",
    "df_test['TotalPorchSF'] = df_test['OpenPorchSF'] + df_test['EnclosedPorch'] + df_test['3SsnPorch'] + df_test['ScreenPorch']\n",
    "\n",
    "# Checking if house has Multiple Floor\n",
    "df_test['2FlrBld'] = df_test['2ndFlrSF'].apply(lambda x: 0 if x==0 else 1)\n",
    "\n",
    "# Checking if Basement is Available with house\n",
    "df_test['BsmtAvailable'] = df_test['BsmtExposure'].apply(lambda x: 0 if x=='NA' else 1)\n",
    "\n",
    "# As we have used some column to create new column, now we can delete the old columns.<br />\n",
    "# In below cell we will drop the columns that isn't required<br />\n",
    "\n",
    "# List of column names need to be dropped as non required / repetational\n",
    "drop_col = ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    "            '1stFlrSF', '2ndFlrSF', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
    "            'HalfBath', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch',\n",
    "            'YrSold', 'BsmtExposure', 'Electrical']\n",
    "\n",
    "# List of column names for which dummy var is to be created\n",
    "dummy_col = ['MoSold', 'GarageType', \n",
    "             'GarageFinish', 'BsmtFinType2', 'BsmtFinType1']\n",
    "\n",
    "# Droping columns mentioned in `drop_col` variable\n",
    "df_test.drop(drop_col, axis=1, inplace=True)\n",
    "\n",
    "# Dropping column with leftover Nan value (Only one row with Nan in Electrical Column!) \n",
    "df_test.dropna(inplace=True)\n",
    "\n",
    "# Reseting the index number after dropping all the missing values\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "new_df = pd.concat([df_test, pd.get_dummies(df_test[dummy_col], drop_first=True)], axis=1)\n",
    "new_df.drop(dummy_col, axis=1, inplace=True)\n",
    "\n",
    "# ## Feature Selection (Quantitaive Feature)\n",
    "# Dropping column with Multi-colinearity\n",
    "new_df.drop(['GarageAge', 'GarageArea'], axis=1, inplace=True)\n",
    "\n",
    "# ## Normalizing data\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "# After Normalizing\n",
    "new_df['LotFrontage'] = np.log(new_df.LotFrontage)\n",
    "\n",
    "new_df['GrLivArea'] = np.log(new_df.GrLivArea)\n",
    "\n",
    "# drop pearson non significant columns\n",
    "new_df.drop(['MSSubClass', 'OverallCond', 'LowQualFinSF', 'PoolArea', 'MiscVal'], axis=1, inplace=True)\n",
    "\n",
    "# ## ANOVA\n",
    "# \n",
    "# Analysis of variance, or ANOVA, is a powerful statistical technique that involves partitioning the observed variance into different components to conduct various significance tests.\n",
    "drop_anova = ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'ExterCond', 'BsmtCond', 'Heating', 'Functional', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n",
    "new_df.drop(drop_anova, axis=1, inplace=True)\n",
    "create_qual_dummies = ['Neighborhood', 'MasVnrType', 'ExterQual', 'Foundation', 'BsmtQual', 'HeatingQC', 'CentralAir', 'KitchenQual', 'FireplaceQu']\n",
    "\n",
    "gradeof5 = {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}\n",
    "gradeof6 = {'NA':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}\n",
    "\n",
    "for col in ['ExterQual', 'HeatingQC', 'KitchenQual']:\n",
    "    new_df[col].replace(gradeof5, inplace=True)\n",
    "    create_qual_dummies.remove(col)\n",
    "\n",
    "for col in ['FireplaceQu', 'BsmtQual']:\n",
    "    new_df[col].replace(gradeof6, inplace=True)\n",
    "    create_qual_dummies.remove(col)\n",
    "\n",
    "new_df = pd.concat([new_df,pd.get_dummies(new_df[create_qual_dummies], drop_first=True)], axis=1)\n",
    "new_df.drop(create_qual_dummies, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "new_df.to_csv('output/dataset/Housing clean test_dataset.csv')\n",
    "\n",
    "count_cols(new_df)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420d72a-013e-4cab-8c75-23cf45aab9a4",
   "metadata": {},
   "source": [
    "The execution time recorded for the test data transformation was `1.03 second`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad83b11d-e0b7-49bc-82a2-5953af20c43d",
   "metadata": {},
   "source": [
    "<h3>Author</h3>\n",
    "<h4>Akash Sharma</h4>\n",
    "<div style=\"float:left\">\n",
    "  <a href=\"https://www.linkedin.com/in/akash-sharma-01775b14a\">\n",
    "    <img src=\"https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white\" alt=\"LinkedIn\">\n",
    "  </a>\n",
    "  <a href=\"https://discord.com/users/366283102462541865\">\n",
    "    <img src=\"https://img.shields.io/badge/Discord-7289DA?style=for-the-badge&logo=discord&logoColor=white\" alt=\"Discord\">\n",
    "  </a>\n",
    "  <a href=\"https://github.com/CosmiX-6\">\n",
    "    <img src=\"https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white\" alt=\"GitHub\">\n",
    "  </a>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
